{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8347253,"sourceType":"datasetVersion","datasetId":4958823}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import openpyxl\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.signal as signal\nimport pywt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-08T14:46:01.522144Z","iopub.execute_input":"2024-05-08T14:46:01.522621Z","iopub.status.idle":"2024-05-08T14:46:02.865266Z","shell.execute_reply.started":"2024-05-08T14:46:01.522580Z","shell.execute_reply":"2024-05-08T14:46:02.864170Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"H_file_wb = openpyxl.load_workbook(\"/kaggle/input/hci-data/output_data.xlsx\")\n# print(H_file_wb.sheetnames)\n\nH_file_ws = H_file_wb['File_Data']\n\ncols = list(H_file_ws.columns)\nnum_cols = int(H_file_ws.max_column)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:46:05.319621Z","iopub.execute_input":"2024-05-08T14:46:05.320133Z","iopub.status.idle":"2024-05-08T14:46:07.143599Z","shell.execute_reply.started":"2024-05-08T14:46:05.320102Z","shell.execute_reply":"2024-05-08T14:46:07.142442Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Define the Butterworth filter parameters\nlowcut = 0.5  # Low cutoff frequency (Hz)\nhighcut = 20  # High cutoff frequency (Hz)\norder = 4  # Filter order\n\n# Initialize lists to store statistical features\nmeans = []\nvariances = []\nstd_devs = []\n\n# Lists to store filtered and preprocessed signals\npreprocessed_signals = []\n\nfor i in range (num_cols):\n    rows_range = cols[i]\n    signal_data = []\n    for a in rows_range[1:]:  # Start from the second row\n        signal_data.append(a.value)\n        signal_data = [float(a.value) for a in rows_range[1:] if a.value is not None]\n\n    #print(signal_data)\n\n    # Plot the original signal\n    plt.figure(figsize=(12, 6))\n    plt.subplot(3, 1, 1)\n    plt.plot(np.arange(0, len(signal_data)), signal_data)\n    plt.xlabel('Time')\n    plt.ylabel('Amplitude')\n    plt.title('Original EOG Signal')\n\n    # Apply Butterworth bandpass filter\n    b, a = signal.butter(order, [lowcut, highcut], btype='band', fs=1000)\n    filtered_signal = signal.filtfilt(b, a, signal_data, axis=0)  # Assuming the signal is stored along axis 0\n\n    # Plot the filtered signal\n    plt.subplot(3, 1, 2)\n    plt.plot(np.arange(0, len(filtered_signal)), filtered_signal)\n    plt.xlabel('Time')\n    plt.ylabel('Amplitude')\n    plt.title('Filtered EOG Signal')\n\n\n    # Remove DC offset\n    dc_offset_removed_signal = filtered_signal - np.mean(filtered_signal)\n\n    # Plot the filtered and DC offset removed signal\n    plt.subplot(3, 1, 3)\n    plt.plot(np.arange(0, len(dc_offset_removed_signal)), dc_offset_removed_signal)\n    plt.xlabel('Time')\n    plt.ylabel('Amplitude')\n    plt.title('Filtered and DC Offset Removed EOG Signal')\n\n    plt.tight_layout()\n#     plt.show()\n#     break\n    plt.close()\n    \n    preprocessed_signals.append(dc_offset_removed_signal)\n    \n    #First Feature Extraction\n    # Calculate statistical features from normalized signal\n    mean_value = np.mean(dc_offset_removed_signal)\n    variance_value = np.var(dc_offset_removed_signal)\n    std_dev_value = np.std(dc_offset_removed_signal)\n\n    # Append the statistical features to the respective lists\n    means.append(mean_value)\n    variances.append(variance_value)\n    std_devs.append(std_dev_value)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:46:11.205972Z","iopub.execute_input":"2024-05-08T14:46:11.207373Z","iopub.status.idle":"2024-05-08T14:47:04.192973Z","shell.execute_reply.started":"2024-05-08T14:46:11.207327Z","shell.execute_reply":"2024-05-08T14:47:04.191823Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(len(preprocessed_signals))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:47:30.740086Z","iopub.execute_input":"2024-05-08T14:47:30.740477Z","iopub.status.idle":"2024-05-08T14:47:30.746845Z","shell.execute_reply.started":"2024-05-08T14:47:30.740447Z","shell.execute_reply":"2024-05-08T14:47:30.745606Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"201\n","output_type":"stream"}]},{"cell_type":"code","source":"#DecisionTree\n#Statistical Features from raw samples\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Load the Excel workbook with class labels\nH_file_wb = openpyxl.load_workbook(\"/kaggle/input/hci-data/output_class.xlsx\")\nH_file_ws = H_file_wb['File_Class']\n\n# Extract class labels, skipping the header\nlabels = []\nfor index, row in enumerate(H_file_ws.iter_rows(values_only=True), start=1):\n    if index > 1:  # Skip the first row (header)\n        labels.append(row[1])  # Assuming class name is in the second column\n\n# Convert lists to NumPy arrays\nX = np.array([means, variances, std_devs]).T  # Features\ny = labels\n\n# Initialize Decision Tree classifier\ntree_clf = DecisionTreeClassifier(random_state=42)\n\n# Perform cross-validation\ncv_scores = cross_val_score(tree_clf, X, labels, cv=5)  # 5-fold cross-validation\n\n# Print cross-validation scores\nprint(\"Cross-Validation Scores:\", cv_scores)\nprint(\"Mean Cross-Validation Score:\", np.mean(cv_scores))\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train Decision Tree classifier\ntree_clf.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred = tree_clf.predict(X_test)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:47:58.356918Z","iopub.execute_input":"2024-05-08T14:47:58.357319Z","iopub.status.idle":"2024-05-08T14:47:58.752057Z","shell.execute_reply.started":"2024-05-08T14:47:58.357289Z","shell.execute_reply":"2024-05-08T14:47:58.750986Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Cross-Validation Scores: [0.19512195 0.325      0.325      0.225      0.175     ]\nMean Cross-Validation Score: 0.2490243902439025\nAccuracy: 0.36585365853658536\n","output_type":"stream"}]},{"cell_type":"code","source":"#RandomForest\n#Statistical Features from raw samples\n\nfrom sklearn.model_selection import train_test_split , cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Load the Excel workbook with class labels\nH_file_wb = openpyxl.load_workbook(\"/kaggle/input/hci-data/output_class.xlsx\")\nH_file_ws = H_file_wb['File_Class']\n\n# Extract class labels, skipping the header\nlabels = []\nfor index, row in enumerate(H_file_ws.iter_rows(values_only=True), start=1):\n    if index > 1:  # Skip the first row (header)\n        labels.append(row[1])  # Assuming class name is in the second column\n\n# Convert lists to NumPy arrays\nX = np.array([means, variances, std_devs]).T  # Features\ny = labels\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.2, random_state=42)\n\n# Initialize Random Forest classifier\nrf_clf = RandomForestClassifier(random_state=42)\n\n# Perform cross-validation\ncv_scores = cross_val_score(rf_clf, X, labels, cv=8)  # 5-fold cross-validation\n\n# Print cross-validation scores\nprint(\"Cross-Validation Scores:\", cv_scores)\nprint(\"Mean Accuracy:\", np.mean(cv_scores))\n\n# Train Random Forest classifier\nrf_clf.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred = rf_clf.predict(X_test)\n\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:48:03.121777Z","iopub.execute_input":"2024-05-08T14:48:03.122200Z","iopub.status.idle":"2024-05-08T14:48:04.838301Z","shell.execute_reply.started":"2024-05-08T14:48:03.122151Z","shell.execute_reply":"2024-05-08T14:48:04.837451Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Cross-Validation Scores: [0.23076923 0.24       0.4        0.24       0.28       0.28\n 0.24       0.16      ]\nMean Accuracy: 0.25884615384615384\nAccuracy: 0.36585365853658536\n","output_type":"stream"}]},{"cell_type":"code","source":"#SVM\n#Statistical Features from raw samples\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nimport openpyxl\n\n# Load the Excel workbook with class labels\nH_file_wb = openpyxl.load_workbook(\"/kaggle/input/hci-data/output_class.xlsx\")\nH_file_ws = H_file_wb['File_Class']\n\n# Extract class labels, skipping the header\nlabels = []\nfor index, row in enumerate(H_file_ws.iter_rows(values_only=True), start=1):\n    if index > 1:  # Skip the first row (header)\n        labels.append(row[1])  # Assuming class name is in the second column\n\n        \n# Convert lists to NumPy arrays\nX = np.array([means, variances, std_devs]).T  # Features\n\n# Initialize SVM classifier\nsvm_clf = SVC(kernel='linear', random_state=42)  # You can change the kernel type as needed\n\n# Perform cross-validation\ncv_scores = cross_val_score(svm_clf, X, labels, cv=10)  # 10-fold cross-validation\n\n# Print cross-validation scores\nprint(\"Cross-Validation Scores:\", cv_scores)\nprint(\"Mean Cross-Validation Score:\", np.mean(cv_scores))\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n\n# Train SVM classifier\nsvm_clf.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred = svm_clf.predict(X_test)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-08T15:38:36.522772Z","iopub.execute_input":"2024-05-08T15:38:36.523187Z","iopub.status.idle":"2024-05-08T15:39:01.262313Z","shell.execute_reply.started":"2024-05-08T15:38:36.523137Z","shell.execute_reply":"2024-05-08T15:39:01.260675Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Cross-Validation Scores: [0.38095238 0.3        0.3        0.45       0.35       0.3\n 0.25       0.4        0.4        0.2       ]\nMean Cross-Validation Score: 0.3330952380952381\nAccuracy: 0.3170731707317073\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **wavelet**","metadata":{}},{"cell_type":"code","source":"# Define the wavelet parameters\nwavelet = 'db1'  # Daubechies wavelet db1\nlevel = 1  # Wavelet decomposition level\n\n# List to store wavelet coefficients for each signal\nwavelet_coeffs_list = []\n\n# Loop over each filtered and preprocessed signal\nfor signal_data in preprocessed_signals:\n    # Perform wavelet decomposition\n    coeffs = pywt.wavedec(signal_data, wavelet, level=level)\n\n    \n    # Append wavelet coefficients to the list\n    wavelet_coeffs_list.append(coeffs)\n\n# Print or use the list of wavelet coefficients as needed\nprint(\"Wavelet coefficients list:\", wavelet_coeffs_list)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#DecisionTree\n#Statistical Features from wavelet coefficients \nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nimport openpyxl\n\n# Load the Excel workbook with class labels\nH_file_wb = openpyxl.load_workbook(\"/kaggle/input/hci-data/output_class.xlsx\")\nH_file_ws = H_file_wb['File_Class']\n\n# Extract class labels, skipping the header\nlabels = []\nfor index, row in enumerate(H_file_ws.iter_rows(values_only=True), start=1):\n    if index > 1:  # Skip the first row (header)\n        labels.append(row[1])  # Assuming class name is in the second column\n\n# Convert the list of wavelet coefficients to NumPy array\nX = np.array(wavelet_coeffs_list)\n\nX = X.reshape(X.shape[0], -1)\n\n# Initialize Decision Tree classifier\ntree_clf = DecisionTreeClassifier(random_state=42)\n\n# Perform cross-validation\ncv_scores = cross_val_score(tree_clf, X, labels, cv=10)  # 5-fold cross-validation\n\n# Print cross-validation scores\nprint(\"Cross-Validation Scores:\", cv_scores)\nprint(\"Mean Cross-Validation Score:\", np.mean(cv_scores))\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n\n# Train Decision Tree classifier\ntree_clf.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred = tree_clf.predict(X_test)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-08T15:01:28.139743Z","iopub.execute_input":"2024-05-08T15:01:28.140342Z","iopub.status.idle":"2024-05-08T15:01:28.554778Z","shell.execute_reply.started":"2024-05-08T15:01:28.140307Z","shell.execute_reply":"2024-05-08T15:01:28.553744Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Cross-Validation Scores: [0.57142857 0.55       0.4        0.55       0.6        0.2\n 0.2        0.55       0.35       0.25      ]\nMean Cross-Validation Score: 0.42214285714285715\nAccuracy: 0.2926829268292683\n","output_type":"stream"}]},{"cell_type":"code","source":"#RandomForest\n#Statistical Features from wavelet coefficients \n\nfrom sklearn.model_selection import train_test_split , cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Load the Excel workbook with class labels\nH_file_wb = openpyxl.load_workbook(\"/kaggle/input/hci-data/output_class.xlsx\")\nH_file_ws = H_file_wb['File_Class']\n\n# Extract class labels, skipping the header\nlabels = []\nfor index, row in enumerate(H_file_ws.iter_rows(values_only=True), start=1):\n    if index > 1:  # Skip the first row (header)\n        labels.append(row[1])  # Assuming class name is in the second column\n\n# Convert the list of wavelet coefficients to NumPy array\nX = np.array(wavelet_coeffs_list)\n\nX = X.reshape(X.shape[0], -1)\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, labels , test_size=0.2, random_state=42)\n\n# Initialize Random Forest classifier\nrf_clf = RandomForestClassifier(random_state=42)\n\n# Perform cross-validation\ncv_scores = cross_val_score(rf_clf, X, labels, cv=8)  # 5-fold cross-validation\n\n# Print cross-validation scores\nprint(\"Cross-Validation Scores:\", cv_scores)\nprint(\"Mean Accuracy:\", np.mean(cv_scores))\n\n# Train Random Forest classifier\nrf_clf.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred = rf_clf.predict(X_test)\n\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T15:13:21.703210Z","iopub.execute_input":"2024-05-08T15:13:21.704183Z","iopub.status.idle":"2024-05-08T15:13:24.783365Z","shell.execute_reply.started":"2024-05-08T15:13:21.704145Z","shell.execute_reply":"2024-05-08T15:13:24.781840Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Cross-Validation Scores: [0.57692308 0.6        0.76       0.72       0.64       0.44\n 0.56       0.64      ]\nMean Accuracy: 0.6171153846153846\nAccuracy: 0.6585365853658537\n","output_type":"stream"}]},{"cell_type":"code","source":"#SVM\n#Statistical Features from wavelet coefficients \n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nimport openpyxl\n\n# Load the Excel workbook with class labels\nH_file_wb = openpyxl.load_workbook(\"/kaggle/input/hci-data/output_class.xlsx\")\nH_file_ws = H_file_wb['File_Class']\n\n# Extract class labels, skipping the header\nlabels = []\nfor index, row in enumerate(H_file_ws.iter_rows(values_only=True), start=1):\n    if index > 1:  # Skip the first row (header)\n        labels.append(row[1])  # Assuming class name is in the second column\n\n# Convert the list of wavelet coefficients to NumPy array\nX = np.array(wavelet_coeffs_list)\n\nX = X.reshape(X.shape[0], -1)\n\n# Initialize SVM classifier\nsvm_clf = SVC(kernel='linear', random_state=42)  # You can change the kernel type as needed\n\n# Perform cross-validation\ncv_scores = cross_val_score(svm_clf, X, labels, cv=5)  # 10-fold cross-validation\n\n# Print cross-validation scores\nprint(\"Cross-Validation Scores:\", cv_scores)\nprint(\"Mean Cross-Validation Score:\", np.mean(cv_scores))\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n\n# Train SVM classifier\nsvm_clf.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred = svm_clf.predict(X_test)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-08T15:37:11.541015Z","iopub.execute_input":"2024-05-08T15:37:11.541411Z","iopub.status.idle":"2024-05-08T15:37:14.970443Z","shell.execute_reply.started":"2024-05-08T15:37:11.541383Z","shell.execute_reply":"2024-05-08T15:37:14.968978Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Cross-Validation Scores: [0.58536585 0.65       0.575      0.5        0.5       ]\nMean Cross-Validation Score: 0.5620731707317074\nAccuracy: 0.5365853658536586\n","output_type":"stream"}]}]}